{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d0c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#url to job search API\n",
    "url = \"https://jsearch.p.rapidapi.com/search\"\n",
    "\n",
    "#query criteria \n",
    "querystring = {\"query\":\"data analyst data scientist\",\"page\":\"1\",\"num_pages\":\"9\",\"date_posted\":\"week\",\n",
    "               \"remote_jobs_only\":\"true\",\"employment_types\":\"FULLTIME\"}\n",
    "\n",
    "\n",
    "#keys\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"XXXXXX\",\n",
    "    \"X-RapidAPI-Host\": \"jsearch.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf81c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initates count to keep track of columns in dataframe\n",
    "count = 1\n",
    "\n",
    "#Keyword dataframe\n",
    "Keywordlst = pd.DataFrame(columns = [\"Keyword\"])\n",
    "\n",
    "#loop through entir list of company job postions\n",
    "for i in range (len(response['data'])):\n",
    "   \n",
    "    #list to temp hold qualifications and responsibilities\n",
    "    desc = []\n",
    "     \n",
    "    #not all job postins have qualifications and responsibilities\n",
    "    #will try to pull these first if not will pull entire job description\n",
    "    #job descriptions have exrta word that could effect ATS score that is \n",
    "    #way it is not prefered\n",
    "    try:\n",
    "        \n",
    "        Q=response['data'][i]['job_highlights']['Qualifications']\n",
    "        R=response['data'][i]['job_highlights']['Responsibilities']\n",
    "        #combines the to into one list \n",
    "        desc = Q + R   \n",
    "    \n",
    "    except:\n",
    "        desc = (response['data'][i]['job_description'])\n",
    "    \n",
    "    #creates a temp text.txt file to store job description\n",
    "    f = open('text.txt','w')\n",
    "    \n",
    "    #writes job description to file element by element\n",
    "    for i in desc:\n",
    "        #if there is a element that can not be read it skips it and goes to the next one\n",
    "        try:\n",
    "            f.write(i)\n",
    "        except:\n",
    "            continue\n",
    "    #closes the writing of the file       \n",
    "    f.close()\n",
    "    \n",
    "    #opens the new text file with the job description\n",
    "    jobDec=open('text.txt').read()\n",
    "    \n",
    "    #starts comparison of resume to job description using text vectorization\n",
    "    text =[jobDec]\n",
    "    \n",
    "    #initates tfidf vectorizer removes stop words\n",
    "    tv = TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "    tvfit = tv.fit_transform(text)\n",
    "    \n",
    "    #gets word list\n",
    "    wordlisttv = tv.get_feature_names()\n",
    "    #puts tfidf into array\n",
    "    countlisttv =tvfit.toarray().sum(axis=0)\n",
    "    #turns array into diconary\n",
    "    wordlist=dict(zip(wordlisttv,countlisttv))\n",
    "\n",
    "    \n",
    "    #loops through all wordsin diconary\n",
    "    for i in wordlist:\n",
    "         \n",
    "        #if key is not in dataframes then adds it to it the list\n",
    "        if i in Keywordlst[\"Keyword\"].values:      \n",
    "            Keywordlst.loc[Keywordlst[\"Keyword\"]==i,count]= wordlist[i]\n",
    "        else:\n",
    "            row = {'Keyword':i, count: wordlist[i]}\n",
    "            Keywordlst = Keywordlst.append(row, ignore_index = True)\n",
    "    #new column name       \n",
    "    count += 1\n",
    "    #removes 'text' file\n",
    "    os.remove('text.txt')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a51586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces missing data with 0 \n",
    "Keywordlst=Keywordlst.fillna(0)\n",
    "#gets average of all columns\n",
    "Keywordlst[\"Job_Avg\"]=Keywordlst.iloc[: , 1:count].mean(axis=1)\n",
    "#drops all collumns except the average\n",
    "Keywordlst=Keywordlst.drop(Keywordlst.iloc[:,1:count], axis=1)\n",
    "#sorts the average column from highest to lowest\n",
    "Keywordlst=Keywordlst.sort_values(by='Job_Avg', ascending=False)\n",
    "#resets the indx used to build ranking\n",
    "Keywordlst.reset_index(inplace = True)\n",
    "#adds a ranking to the job description at the first column location\n",
    "Keywordlst.insert(loc = 0, \n",
    "                  column = 'Job Desc Rank',\n",
    "                  value =Keywordlst.index+1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86dea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare your resume to job search list\n",
    "\n",
    "#resuem to check against job descriptions\n",
    "\n",
    "resume = docx2txt.process(\"King_Resume_ds_2_final.docx\")\n",
    "\n",
    "\n",
    "#starts comparison of resume to job description using text vectorization\n",
    "Restext =[resume]\n",
    "    \n",
    "#initates tfidf vectorizer removes stop words\n",
    "Restvfit = tv.fit_transform(Restext)\n",
    "    \n",
    "#gets word list\n",
    "wordlistRes = tv.get_feature_names()\n",
    "#puts tfidf into array\n",
    "countlistRes =Restvfit.toarray().sum(axis=0)\n",
    "#turns array into diconary\n",
    "wordlistRes=dict(zip(wordlistRes ,countlistRes))\n",
    "\n",
    "#creates dataframe to hold resume TfIdf score\n",
    "Resume_df = pd.DataFrame(columns = [\"Keyword\", \"Resume Score\"])\n",
    "\n",
    "#loops through all words from resume put into dictonary\n",
    "for i in wordlistRes:\n",
    "    #creates row to append to dataframe\n",
    "    row = {'Keyword':i, \"Resume Score\": wordlistRes[i]}\n",
    "    Resume_df = Resume_df.append(row, ignore_index = True)\n",
    "\n",
    "#sorts keywords by resume score    \n",
    "Resume_df=Resume_df.sort_values(by='Resume Score', ascending=False)\n",
    "#Resets index so that a ranking can be doen\n",
    "Resume_df.reset_index(inplace = True)\n",
    "#Creates rank column for resume keyword\n",
    "Resume_df['Rank'] = Resume_df.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be28bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergers keywordlist and Resume_df into one dataframe\n",
    "KeywordlstMerge = pd.merge(Keywordlst,Resume_df, on = 'Keyword', how = \"outer\")\n",
    "\n",
    "#removes the index column from the keywordlist and resume_df dataframe\n",
    "KeywordlstMerge=KeywordlstMerge.drop(KeywordlstMerge.columns[[1,4]],axis = 1)\n",
    "#add column for the number of job descriptions searched\n",
    "KeywordlstMerge['Job count']= \"\"\n",
    "#count of jobs pulled to ket keyword list\n",
    "KeywordlstMerge.at[0, 'Job count'] = len(response['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0cd23bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job finished\n"
     ]
    }
   ],
   "source": [
    "#exports keywordlstMerge freeszes first row and does not print index\n",
    "KeywordlstMerge.to_excel(\"keyword.xlsx\",freeze_panes=(1,0), index=False)\n",
    "print(\"job finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46a809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
